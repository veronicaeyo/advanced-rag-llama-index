{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Auto-merging Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"pdfs/eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: a5e2a1fb-7cf6-4619-9609-329a826c85b8\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-merging retrieval setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import HierarchicalNodeParser\n",
    "\n",
    "# create the hierarchical node parser w/ default settings\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048, 512, 128]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took centuries for literacy to spread, and now society is far richer for it.\n",
      "Words enable deep human-to-human communication. Code is the deepest form of human-to-\n",
      "machine communication. As machines become more central to daily life, that communication \n",
      "becomes ever more important.\n",
      "Traditional software engineering — writing programs that explicitly tell a computer sequences \n",
      "of steps to execute — has been the main path to code literacy. Many introductory programming \n",
      "classes use creating a video game or building a website as examples. But AI, machine learning, \n",
      "and data science offer a new paradigm in which computers extract knowledge from data.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.node_parser import get_leaf_nodes\n",
    "\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "print(leaf_nodes[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(leaf_nodes[3].text, \"cl100k_base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGE 12Should You \n",
      "Learn Math to \n",
      "Get a Job in AI? CHAPTER 3\n",
      "LEARNING\n",
      "\n",
      "PAGE 13Should you Learn Math to Get a Job in AI? CHAPTER 3\n",
      "Is math a foundational skill for AI? It’s always nice to know more math! But there’s so much to \n",
      "learn that, realistically, it’s necessary to prioritize. Here’s how you might go about strengthening \n",
      "your math background.\n",
      "To figure out what’s important to know, I find it useful to ask what you need to know to make \n",
      "the decisions required for the work you want to do. At DeepLearning.AI, we frequently ask, \n",
      "“What does someone need to know to accomplish their goals?” The goal might be building a \n",
      "machine learning model, architecting a system, or passing a job interview.\n",
      "Understanding the math behind algorithms you use is often helpful, since it enables you to \n",
      "debug them. But the depth of knowledge that’s useful changes over time. As machine learning \n",
      "techniques mature and become more reliable and turnkey, they require less debugging, and a \n",
      "shallower understanding of the math involved may be sufficient to make them work.\n",
      "For instance, in an earlier era of machine learning, linear algebra libraries for solving linear \n",
      "systems of equations (for linear regression) were immature. I had to understand how these \n",
      "libraries worked so I could choose among different libraries and avoid numerical roundoff \n",
      "pitfalls. But this became less important as numerical linear algebra libraries matured.\n",
      "Deep learning is still an emerging technology, so when you train a neural network and the \n",
      "optimization algorithm struggles to converge, understanding the math behind gradient \n",
      "descent, momentum, and the Adam  optimization algorithm will help you make better decisions. \n",
      "Similarly, if your neural network does something funny — say, it makes bad predictions on \n",
      "images of a certain resolution, but not others — understanding the math behind neural network \n",
      "architectures puts you in a better position to figure out what to do.\n",
      "Of course, I also encourage learning driven by curiosity. If something interests you, go ahead \n",
      "and learn it regardless of how useful it might turn out to be!  Maybe this will lead to a creative \n",
      "spark or technical breakthrough.How much math do you need to know to be a machine learning engineer?\n"
     ]
    }
   ],
   "source": [
    "nodes_by_id = {node.node_id: node for node in nodes}\n",
    "\n",
    "parent_node = nodes_by_id[leaf_nodes[30].parent_node.node_id]\n",
    "print(parent_node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(parent_node.text, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a markdown file writing the steps taken sentence window retriever and auto mergin retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "auto_merging_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "automerging_index = VectorStoreIndex(\n",
    "    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context\n",
    ")\n",
    "\n",
    "automerging_index.storage_context.persist(persist_dir=\"./merging_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is optional to check\n",
    "# if an index file exist, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "import os\n",
    "from llama_index import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "if not os.path.exists(\"./merging_index\"):\n",
    "    automerging_index = VectorStoreIndex(\n",
    "        leaf_nodes,\n",
    "        storage_context=storage_context,\n",
    "        service_context=auto_merging_context,\n",
    "    )\n",
    "\n",
    "    automerging_index.storage_context.persist(persist_dir=\"./merging_index\")\n",
    "else:\n",
    "    automerging_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=\"./merging_index\"),\n",
    "        service_context=auto_merging_context,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the retriever and running the query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "automerging_retriever = automerging_index.as_retriever(\n",
    "    similarity_top_k=12\n",
    ")\n",
    "\n",
    "retriever = AutoMergingRetriever(\n",
    "    automerging_retriever, \n",
    "    automerging_index.storage_context, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "rerank = SentenceTransformerRerank(top_n=6, model=\"BAAI/bge-reranker-base\")\n",
    "\n",
    "auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "    automerging_retriever, node_postprocessors=[rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_merging_response = auto_merging_engine.query(\n",
    "    \"What is the importance of networking in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Networking is important in AI because it allows individuals to build a strong professional network and community. This network can provide valuable information, help with career advancement, and offer support and advice when needed. By connecting with others in the AI community, individuals can also increase their visibility and recognition for their expertise. Additionally, networking can lead to referrals for potential job opportunities. Building a community and network in AI is seen as more beneficial than simply focusing on personal connections, as it allows for the exchange of ideas and the opportunity to make friends."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_response\n",
    "\n",
    "display_response(auto_merging_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.node_parser import HierarchicalNodeParser\n",
    "from llama_index.node_parser import get_leaf_nodes\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "def build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    merging_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
    "        )\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=merging_context,\n",
    "        )\n",
    "    return automerging_index\n",
    "\n",
    "\n",
    "def get_automerging_query_engine(\n",
    "    automerging_index,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=6,\n",
    "):\n",
    "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retriever = AutoMergingRetriever(\n",
    "        base_retriever, automerging_index.storage_context, verbose=True\n",
    "    )\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever, node_postprocessors=[rerank]\n",
    "    )\n",
    "    return auto_merging_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "index = build_automerging_index(\n",
    "    [document],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./merging_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_automerging_query_engine(index, similarity_top_k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Networking is important in AI because it allows individuals to build a strong professional network that can help propel them forward in their careers. By connecting with others in the AI community, individuals can receive help and advice when needed, as well as recognition for their expertise. Additionally, networking can lead to opportunities for collaboration and the sharing of knowledge and resources. Overall, having a strong network in AI can contribute to personal and professional growth in the field."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(query_engine.query(\"What is the importance of networking in AI?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TruLens Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tru was already initialized. Cannot change database_url=sqlite:///db/auto_merging.sqlite or database_file=None .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru(database_url=\"sqlite:///db/auto_merging.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto_merging_index_0 = build_automerging_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index_0\",\n",
    "    chunk_sizes=[2048,512],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_merging_engine_0 = get_automerging_query_engine(\n",
    "    auto_merging_index_0,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(\n",
    "    auto_merging_engine_0,\n",
    "    app_id ='app_0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('text/generated_questions.text', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evals(eval_questions, tru_recorder, query_engine):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: 8496a448-3ef7-4726-8a36-64b4cd561687.\n",
      "> Parent node text: PAGE 20Working on projects requires making tough choices about what to build and how to go \n",
      "about...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 979502cc-42c0-4243-87ab-14e87403922a.\n",
      "> Parent node text: PAGE 7These phases apply in a wide \n",
      "range of professions, but AI \n",
      "involves unique elements.\n",
      "For e...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 5d557aa8-e56d-4fc3-91af-afa161406a86.\n",
      "> Parent node text: PAGE 18It goes without saying that we should only work on projects that are responsible, ethical,...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: c157ff26-12c6-431a-9c0b-7a1fa0458b7f.\n",
      "> Parent node text: PAGE 22Over the course of a career, you’re likely to work on projects in succession, each growing...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 96e9b122-70d6-4d90-80f5-a58e0dc5ee18.\n",
      "> Parent node text: PAGE 15One of the most important skills of an AI architect is the ability to identify ideas that ...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 350ffec5-ebea-46ef-ad79-1f6023e53a4f.\n",
      "> Parent node text: PAGE 23Each project is only one step on a longer journey, hopefully one that has a positive impac...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 33ab1bc3-13f6-4002-a253-2f32c9385af1.\n",
      "> Parent node text: PAGE 16Determine milestones. Once you’ve deemed a project sufficiently \n",
      "valuable, the next step i...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 5c4f0c43-9662-4a95-9383-b972e5667775.\n",
      "> Parent node text: PAGE 29If you’re preparing to switch roles (say, taking a job as a machine learning engineer for ...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 2e903495-2db1-4950-9bad-9c7ffe5f47f0.\n",
      "> Parent node text: PAGE 3Table of \n",
      "ContentsIntroduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Ca...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 48d4f117-c5b8-4624-9bc0-0638025ea805.\n",
      "> Parent node text: PAGE 27There’s a lot we don’t know about the future: When will we cure Alzheimer’s disease? Who w...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: c470405e-72c6-4de5-bb33-ca459811832c.\n",
      "> Parent node text: PAGE 6The rapid rise of AI has led to a rapid rise in AI jobs, and many people are building excit...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder, auto_merging_engine_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [latency, total_cost]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64159febdad3456791fc12e946ac2eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.1.74:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tru' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tru\u001b[38;5;241m.\u001b[39mstop_dashboard()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tru' is not defined"
     ]
    }
   ],
   "source": [
    "# tru.stop_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import get_prebuilt_trulens_recorder\n",
    "from typing import List\n",
    "\n",
    "def build_eval_layer(chunk_sizes: List[int], num_layers: int):\n",
    "\n",
    "    auto_merging_index = build_automerging_index(\n",
    "        documents,\n",
    "        llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "        embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "        save_dir=f\"merging_index_{num_layers}\",\n",
    "        chunk_sizes=chunk_sizes,\n",
    "    )\n",
    "\n",
    "    auto_merging_engine = get_automerging_query_engine(\n",
    "        auto_merging_index,\n",
    "        similarity_top_k=12,\n",
    "        rerank_top_n=6,\n",
    "    )\n",
    "\n",
    "    tru_recorder = get_prebuilt_trulens_recorder(\n",
    "        auto_merging_engine,\n",
    "        app_id =f'num_Layers-{num_layers}'\n",
    "    )\n",
    "\n",
    "    return tru_recorder\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_2 = build_eval_layer(chunk_sizes=[2048, 512], num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('text/generated_questions.text', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evals(eval_questions, tru_recorder, C):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as _:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x205ce82db10 is calling an instrumented method <function BaseQueryEngine.query at 0x00000205C63537E0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x205ce82f890) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x205ce82db10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x00000205CE5322A0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x205ce82f890) using this function.\n",
      "A new object of type <class 'llama_index.retrievers.auto_merging_retriever.AutoMergingRetriever'> at 0x205dfde6ed0 is calling an instrumented method <function BaseRetriever.retrieve at 0x00000205C8DA3C40>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x205e045db10) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x205d29faf50 is calling an instrumented method <function BaseRetriever.retrieve at 0x00000205C8DA3C40>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x205e045db10) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 6078d7c0-502d-41c7-8b9e-36d40ee29a41.\n",
      "> Parent node text: When taking a shot is inexpensive, it also makes sense to take many shots. In this \n",
      "case, the pro...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x205e02d5910 is calling an instrumented method <function CompactAndRefine.get_response at 0x00000205C8DA0540>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x205ce82e890) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x205e02d5910 is calling an instrumented method <function Refine.get_response at 0x00000205C8DA19E0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x205ce82e890) using this function.\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_2, query_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_Layers-2</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Context Relevance  Answer Relevance  latency  total_cost\n",
       "app_id                                                                \n",
       "num_Layers-2              0.575               0.9     26.0    0.001729"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "Tru().get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.1.74:8501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tru().run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_3 = build_eval_layer(chunk_sizes=[2048, 512, 128], num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x205ce82db10 is calling an instrumented method <function BaseQueryEngine.query at 0x00000205C63537E0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x205e2643890) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x205ce82db10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x00000205CE5322A0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x205e2643890) using this function.\n",
      "A new object of type <class 'llama_index.retrievers.auto_merging_retriever.AutoMergingRetriever'> at 0x205dfde6ed0 is calling an instrumented method <function BaseRetriever.retrieve at 0x00000205C8DA3C40>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x205d308a1d0) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x205d29faf50 is calling an instrumented method <function BaseRetriever.retrieve at 0x00000205C8DA3C40>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x205d308a1d0) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 6078d7c0-502d-41c7-8b9e-36d40ee29a41.\n",
      "> Parent node text: When taking a shot is inexpensive, it also makes sense to take many shots. In this \n",
      "case, the pro...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x205e02d5910 is calling an instrumented method <function CompactAndRefine.get_response at 0x00000205C8DA0540>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x205e2642d10) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x205e02d5910 is calling an instrumented method <function Refine.get_response at 0x00000205C8DA19E0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x205e2642d10) using this function.\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_3, query_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_Layers-2</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_Layers-3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Context Relevance  Answer Relevance  Groundedness  latency  \\\n",
       "app_id                                                                     \n",
       "num_Layers-2              0.575               0.9      0.666667     27.0   \n",
       "num_Layers-3                NaN               1.0           NaN     27.0   \n",
       "\n",
       "              total_cost  \n",
       "app_id                    \n",
       "num_Layers-2    0.001729  \n",
       "num_Layers-3    0.001809  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.1.74:8501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
